{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##NLP - Tokenization Process"
      ],
      "metadata": {
        "id": "bhkzwvqTVnRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenization"
      ],
      "metadata": {
        "id": "wsriy3hCaeV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> With nltk\n",
        "\n"
      ],
      "metadata": {
        "id": "WEP3WClVakcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNBt3ym7StcW",
        "outputId": "c70c5eef-4b23-48af-fc35-7eda2721bfbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"Hi, my name is Brown. How are you?\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = nltk.word_tokenize(text)\n",
        "sent_tokens = nltk.sent_tokenize(text)"
      ],
      "metadata": {
        "id": "Hg7E7Mw8S5k3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_tokens)\n",
        "print(sent_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW4x_sD8TFkH",
        "outputId": "231eb013-f44f-4c1d-9a34-c9753b206136"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', ',', 'my', 'name', 'is', 'Brown', '.', 'How', 'are', 'you', '?']\n",
            "['Hi, my name is Brown.', 'How are you?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "tokenize.sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AHmNEsrTMX1",
        "outputId": "2552db86-a8e1-4de2-e4f2-ed42511336f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi, my name is Brown.', 'How are you?']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize.word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spNb5iNtViZL",
        "outputId": "27539eda-c873-4ef5-c9e1-33d9c8d99a35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', ',', 'my', 'name', 'is', 'Brown', '.', 'How', 'are', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> With spacy\n",
        "\n"
      ],
      "metadata": {
        "id": "t6Q8vXN1ayyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "EYIXalQHV6lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "text1 = \"The movie is a hit.\"\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text1)\n",
        "\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJseAYo2WErF",
        "outputId": "a5b46449-c1ba-414c-86c1-eaa9dcd15d1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'movie', 'is', 'a', 'hit', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stemming"
      ],
      "metadata": {
        "id": "jxRu-O3ibC_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> With nltk lemmantizer\n",
        "\n"
      ],
      "metadata": {
        "id": "gevPtt7QbG_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SJiELxXTddq",
        "outputId": "399206c7-3ae9-4253-9750-3834f35827b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"drawing\"\n",
        "\n",
        "morph_analysis = nltk.stem.WordNetLemmatizer().lemmatize(word,pos='v')\n",
        "\n",
        "print(morph_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT02DBtOXWJz",
        "outputId": "7cf4a545-7cea-4994-c26c-031c9dc76d1f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "draw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> With nltk porterstemmer\n",
        "\n"
      ],
      "metadata": {
        "id": "MdGKHG3ZbPIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmer_word = stemmer.stem(word)\n",
        "\n",
        "print(stemmer_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n50DWwUXlbc",
        "outputId": "25fad355-67ce-4467-ac3d-8b6b7a292c69"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "draw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> With spacy\n",
        "\n"
      ],
      "metadata": {
        "id": "iziQJq16bTkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "lemmatized_word = nlp(word)[0].lemma_\n",
        "\n",
        "print(lemmatized_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL10zCjvYd8x",
        "outputId": "bede085f-67d1-411f-c211-9d9db26c803f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "draw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Distance"
      ],
      "metadata": {
        "id": "mjIhnNPo69mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "str0 = \"punched\"\n",
        "str1 = \"punching\"\n",
        "\n",
        "distance = nltk.edit_distance(str0, str1)\n",
        "\n",
        "distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i4It_PaZVZo",
        "outputId": "ab0eb7f6-712b-4c1a-e8c5-a8ae4bbf47b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ngrams"
      ],
      "metadata": {
        "id": "dvAcm2b37K1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "text = \"I did not want to join a band, so I started my own.\"\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "unigrams = ngrams(tokens, 2)\n",
        "\n",
        "for gram in unigrams:\n",
        "    print(gram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1o38hrFZZ1o",
        "outputId": "7c8fff7d-007d-49ca-d431-64c560b200e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I', 'did')\n",
            "('did', 'not')\n",
            "('not', 'want')\n",
            "('want', 'to')\n",
            "('to', 'join')\n",
            "('join', 'a')\n",
            "('a', 'band')\n",
            "('band', ',')\n",
            "(',', 'so')\n",
            "('so', 'I')\n",
            "('I', 'started')\n",
            "('started', 'my')\n",
            "('my', 'own')\n",
            "('own', '.')\n"
          ]
        }
      ]
    }
  ]
}